[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Everyone",
    "section": "",
    "text": "Preface\nData science is everywhere around us—from the maps that guide our commutes, to the movie recommendations we receive, to the health and environmental reports that help shape public policy. Yet for many students, data science feels distant, complicated, or reserved for college courses. This book takes the opposite view. With the right tools and a curious mindset, anyone—especially high school students—can begin doing real data science today.\nThe goal of this book is to show you what data science actually looks like in practice. It focuses not on memorizing formulas, but on learning how to set up your computer correctly, organize your work, use modern tools such as the command line, Git, VS Code, and Quarto, and build reproducible analyses from day one. These skills form the foundation of professional data science, and developing them early will allow you to create insights that matter.\nThroughout the book, you will work with real datasets from topics you already care about: sports, the environment, health, city life, and more. You will learn how to explore the data, ask thoughtful questions, create visualizations, and communicate your findings clearly. Just as importantly, you will learn how to manage your work like a professional data scientist, building good habits that will serve you through college and beyond.\nThis book assumes no prior experience with programming or statistics. What it does assume is curiosity, patience, and a willingness to try. You will write your first command-line commands, make your first Git commits, produce your first Quarto report, and build your first real project—all in Part I. Part II will invite you to discover patterns in real-world datasets through guided examples.\nMy hope is that this book helps you see data science not as something mysterious, but as something you can do, enjoy, and grow with. Every data scientist started where you are now—with a blank screen, an open mind, and a desire to understand the world better.\nWelcome to your journey into data science.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  What Is Data Science?",
    "section": "",
    "text": "1.1 Data Science Is About Asking Questions\nData science is the practice of learning from data. It brings together three pillars—computation, statistics, and domain knowledge—to create insights that help us understand, predict, and improve the world around us. You have already seen data science in action many times without noticing it.\nThis chapter introduces what data science is and what it is not, setting the stage for the hands-on tools you will learn in Part I.\nEvery data science project begins with a question.\nWhy has traffic increased on my school’s street?\nDo certain neighborhoods file more noise complaints?\nWhich players contributed most to a team’s winning season?\nData science helps translate these questions into something we can analyze, measure, and explain.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Data Science?</span>"
    ]
  },
  {
    "objectID": "01-intro.html#data-science-uses-tools-not-just-math",
    "href": "01-intro.html#data-science-uses-tools-not-just-math",
    "title": "1  What Is Data Science?",
    "section": "1.2 Data Science Uses Tools, Not Just Math",
    "text": "1.2 Data Science Uses Tools, Not Just Math\nWhile math is important for deeper understanding, data scientists spend much of their time using tools—command line, Git, VS Code, Quarto, and programming languages such as Python or R. These tools help you:\n\nload and clean data\norganize your work\nbuild reproducible workflows\ncreate visualizations\nshare results with others\n\nThis book starts with tools because tools give you the power to actually do data science. Once you know how to work with your computer the way data scientists do, everything else becomes easier.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Data Science?</span>"
    ]
  },
  {
    "objectID": "01-intro.html#data-science-is-reproducible",
    "href": "01-intro.html#data-science-is-reproducible",
    "title": "1  What Is Data Science?",
    "section": "1.3 Data Science Is Reproducible",
    "text": "1.3 Data Science Is Reproducible\nA key idea in this book is reproducibility. A reproducible workflow is one where:\n\nyour analysis is neatly organized\nevery step is documented\nresults can be reproduced exactly by you or anyone else\n\nThis is why you will learn Quarto for writing reports and Git for version control. These skills turn your projects into something professional, even as a beginner.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Data Science?</span>"
    ]
  },
  {
    "objectID": "01-intro.html#data-science-is-interdisciplinary",
    "href": "01-intro.html#data-science-is-interdisciplinary",
    "title": "1  What Is Data Science?",
    "section": "1.4 Data Science Is Interdisciplinary",
    "text": "1.4 Data Science Is Interdisciplinary\nTo answer real-world questions, you combine:\n\ncomputing — writing code to process data\nstatistics — measuring uncertainty and learning patterns\ndomain knowledge — understanding the context: climate, health, sports, education, city systems, and many others\n\nNone of these pillars works alone. Together they create meaningful insights.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Data Science?</span>"
    ]
  },
  {
    "objectID": "01-intro.html#what-you-will-learn-next",
    "href": "01-intro.html#what-you-will-learn-next",
    "title": "1  What Is Data Science?",
    "section": "1.5 What You Will Learn Next",
    "text": "1.5 What You Will Learn Next\nPart I of this book focuses on building your foundation:\n\nusing the command line\nnavigating your computer\ncreating projects with clean structure\nusing VS Code as your editing home\ntracking your work with Git\nwriting analyses with Quarto\nlearning your first programming language (Python)\n\nBy the end of Part I, you will have built your first complete data science project: a real report, with real data, that you can publish or share.\nPart II takes you through case studies in health, environment, sports, and other areas—helping you discover patterns in real datasets and understand how data science works in practice.\nData science is not something you learn in one day. It is a craft you build over time. This book gives you the tools and the mindset to begin that journey the right way.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Data Science?</span>"
    ]
  },
  {
    "objectID": "02-computer.html",
    "href": "02-computer.html",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "",
    "text": "2.1 Introduction\nMany people use computers only through apps, clicking buttons designed by someone else. Data science works differently. Instead of staying inside fixed menus, you will learn to give the computer precise instructions so it can help you ask questions, test ideas, and make new discoveries. Thinking of the computer as a programmable machine opens a new way of working: your results become something you can recreate, improve, and share.\nA key step toward this mindset is understanding how a computer organizes information. Every file on your machine lives in a folder, and every folder has a path that tells the computer exactly where it is. Data scientists work directly with these paths because tools such as Python, R, Git, and Quarto all expect you to know where your work lives. When you understand the file system, you can tell your tools exactly which data to use and where to save your results.\nMuch of data science relies on plain-text files. These include data files like .csv, scripts like .py or .R, and documents like .qmd. Plain text is transparent: you can open it anywhere, track changes, and process it automatically. This clarity is the reason modern analysis avoids mixing computation with formatting. In contrast, spreadsheets hide steps inside cells, and slides require manual updates each time your results change. They are useful for quick checks but cannot support serious analysis where every step must be clear.\nThis leads to one of the most important ideas in data science: reproducibility. Your future self and anyone who reads your work should be able to start with your raw data and code and arrive at the same results. Reproducibility protects you from accidental mistakes, forgotten steps, and lost work. It turns your analysis into something reliable, explainable, and extendable. As you progress through this book, everything you do will be built with reproducibility in mind.\nThis chapter sets the foundation for the tools that follow. Once you see your computer as a programmable partner rather than a collection of apps, learning the command line, version control, and reproducible documents becomes natural.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "02-computer.html#whats-inside-your-computer",
    "href": "02-computer.html#whats-inside-your-computer",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "2.2 What’s Inside Your Computer",
    "text": "2.2 What’s Inside Your Computer\nBefore we talk to the computer through the command line, it helps to know what is inside the box. You do not need to become a hardware expert, but a few ideas will make later chapters much easier to understand.\nAt a high level, every computer used for data science has four key parts:\n\nCPU (Central Processing Unit)\nThe CPU is the “brain” of the computer. It follows instructions one step at a time and does the general-purpose work in your programs.\nRAM (Random-Access Memory)\nRAM is the computer’s short-term memory. When you open a dataset in Python or R, it is copied into RAM so the CPU can work with it quickly. If you do not have enough RAM, large projects slow down or crash.\nStorage (SSD or hard drive)\nStorage is the long-term memory. Your files, photos, code, and datasets live here even after you shut down the computer. Solid-state drives (SSD) are faster and more reliable than older spinning hard drives.\nGPU (Graphics Processing Unit)\nThe GPU started as a special chip for drawing graphics and games. Modern data science uses GPUs for huge math problems, such as training deep learning models, because they can do many simple calculations in parallel.\n\nYou can think of the CPU as a student solving math problems, RAM as the open notebook on the desk, storage as the backpack and bookshelf, and the GPU as a team of helpers who can all work on similar problems at the same time.\n\n\n\n\n\n\nNote⭐ Advanced: How Much Is “Enough”?\n\n\n\n\n\nFor small school projects, almost any modern laptop will work. As you move toward bigger datasets and models, more RAM usually helps more than more CPU cores. If you often run out of memory when loading data, adding RAM or moving to a machine with more RAM makes a big difference. GPUs become important mainly for large deep learning or image-heavy projects.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "02-computer.html#operating-systems-and-why-professionals-love-linux",
    "href": "02-computer.html#operating-systems-and-why-professionals-love-linux",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "2.3 Operating Systems and Why Professionals Love Linux",
    "text": "2.3 Operating Systems and Why Professionals Love Linux\nAn operating system (OS) is the layer of software that connects your programs to the hardware. It controls files, devices, memory, and how programs run. The three main families you will see in data science are Windows, macOS, and Linux.\n\nLinux\nLinux is the standard in professional data science and on almost all servers and cloud machines. It is predictable: nothing major happens behind your back. When you install software or change a setting, it stays that way until you change it again. The command line tools you learn in this book behave the same way on almost every Linux system.\nmacOS\nmacOS is based on Unix, like Linux, and includes a built-in terminal that understands almost all the same commands. Many data scientists who use laptops choose macOS because it balances a friendly interface with powerful command line tools.\nWindows\nWindows makes it easy to start, but it also tries to “help” by hiding file extensions, changing paths, and running background tools that can confuse reproducible work. Different parts of Windows sometimes disagree about how to name files or run commands. These shortcuts can be convenient for everyday use but can teach habits that do not transfer well to Linux or the cloud.\n\nIn this book, we will prefer a Unix-style command line everywhere. On macOS and Linux, that means using the built-in Terminal app. On Windows, that means installing and using Git Bash, which brings a Unix-like terminal to Windows so that the same commands work on all three platforms.\n\n2.3.1 Installing Software from the Command Line\nData scientists often install tools using package managers, which are programs that download, install, and update software for you from the command line. This is faster, more repeatable, and easier to document than clicking through many installer windows.\nHere are the most common options:\n\nLinux\nEach Linux distribution comes with its own package manager. For example: apt on Ubuntu, dnf on Fedora, and pacman on Arch. These tools let you install almost everything you need with a single command.\nmacOS\nOn macOS, the most popular package manager is Homebrew. After installing Homebrew once, you can run commands like brew install git or brew install python to get new tools.\nWindows\nOn Windows 10 and 11, you can use winget from the command line to install software. Once Git Bash is installed and set up, you can run commands such as\nwinget install Python.Python.3.12\nwinget install Git.Git\nwinget install RProject.R\nwinget install Quarto.Quarto\nfrom a terminal and let Windows handle the downloads and installation steps.\n\n\n\n\n\n\n\nNote⭐ Advanced: Other Options on Windows\n\n\n\n\n\nSome developers use full Linux environments on Windows through the Windows Subsystem for Linux (WSL) or alternative package managers such as Chocolatey. These are powerful options when you do a lot of development on Windows, but you do not need them for this book.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "02-computer.html#how-computers-represent-numbers",
    "href": "02-computer.html#how-computers-represent-numbers",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "2.4 How Computers Represent Numbers",
    "text": "2.4 How Computers Represent Numbers\nComputers are built on binary, a number system that uses only zeros and ones. That design works well for storing whole numbers, but it creates some surprises when we work with decimals.\nThere are two basic kinds of numbers you will see in data science:\n\nIntegers (…, -2, -1, 0, 1, 2, …)\nThese are whole numbers with no decimal part. Computers can store many integers exactly.\nFloating-point numbers (like 0.1, 2.75, or -3.14)\nThese are used for decimals and measurements. Most real-valued data in science and statistics are stored as floating-point numbers.\n\nBecause computers use binary, many simple-looking decimals cannot be stored exactly. For example, the decimal number 0.1 turns into a long repeating pattern in binary. The computer stores a very close approximation instead of the exact value. When you combine many such numbers, the tiny differences can show up as small rounding errors.\nYou may have seen examples where a language reports that 0.1 + 0.2 is 0.30000000000000004 instead of exactly 0.3. This is not a bug in Python or R. It is a consequence of how floating-point numbers are stored in hardware. Data scientists work with this by rounding results for display and by avoiding direct equality checks with decimals.\nThe key ideas to remember are:\n\nSome decimals cannot be represented exactly on a computer.\nSmall rounding differences are normal in real-number calculations.\nWe usually care about being “close enough” rather than perfectly exact.\n\n\n\n\n\n\n\nNote⭐ Advanced: Why This Matters in Data Science\n\n\n\n\n\nThe standard format for floating-point numbers in most languages is called IEEE 754. It trades exactness for speed and a wide range of values. When you compare floating-point results across languages or machines, tiny differences are expected. When results must be exactly reproducible bit-for-bit, experts sometimes use special libraries, exact arithmetic, or careful control of the hardware and compiler settings.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "02-computer.html#the-command-line-speaking-your-computers-language",
    "href": "02-computer.html#the-command-line-speaking-your-computers-language",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "2.5 The Command Line: Speaking Your Computer’s Language",
    "text": "2.5 The Command Line: Speaking Your Computer’s Language\nMost people use computers through windows, buttons, and icons. The command line offers a different approach: you type short instructions that the computer understands directly. This way of working gives you transparency, repeatability, and control that clicking cannot provide. Data science relies on these qualities because your work must be clear, sharable, and reproducible. On Windows, you will use Git Bash; on macOS or Linux, you will use the Terminal app.\n\n2.5.1 What the Command Line Is and Why Data Scientists Use It\nThe command line is an interface where you communicate with the computer by typing commands. Each command performs one well-defined action. Because every action appears plainly on the screen, the command line makes your steps visible and traceable. This transparency helps you understand what you are doing, and it allows others to follow your work. Clicking through menus, by contrast, leaves no reliable record. The command line also supports automation: a command that you type once can be saved in a script and reused whenever you need it. This repeatability is a cornerstone of reproducible data science.\nWhen you write commands in a script and save them in a file, the computer can repeat those steps exactly. If you make a mistake, you can correct the script and run it again. If a friend wants to understand your analysis, you can send them the script instead of trying to describe what you clicked. This practice of scripting is at the heart of reproducible data science.\nThe command line also gives you access to tools that do not have a graphical interface at all. Many powerful utilities, including Git for version control and Quarto for reproducible documents, are designed to be run from the terminal. Learning the command line opens the door to these tools and lets you combine them in flexible ways.\nAt first, the command line may feel slower than clicking. That feeling fades as you learn the basic commands. Eventually, you will be able to move through folders, manage files, and run complex workflows with just a few keystrokes. Small scripts you write today can become the building blocks for larger projects later.\n\n\n2.5.2 Navigating Your System\nWhen you open Git Bash or Terminal, you start in a current working directory — the folder where the computer assumes you want to work. The commands you type will use this folder unless you tell them otherwise. To use the command line effectively, you need to know where you are and how to move around.\nThe key commands for navigation are:\n\npwd — print working directory (shows your current folder)\n\nls — list files and folders in the current directory\n\ncd &lt;path&gt; — change directory to the folder given by &lt;path&gt;\n\nPaths come in two flavors:\n\nAbsolute paths start from the root of the file system and show the full route to a folder.\n\nRelative paths start from your current location and describe how to get somewhere from there.\n\nFor example, on a typical system your home directory might be something like /Users/alex on macOS or Linux, or C:\\Users\\alex on Windows. In Git Bash, the Windows path will appear in a Unix-style form such as /c/Users/alex. If you are in your home directory and you want to move to a subfolder called projects, you can run cd projects. If you are somewhere else and want to jump straight to your home directory, you can use cd ~.\nThe .. symbol means “the parent directory” — the folder that contains the one you are in:\n\ncd .. moves you up one level.\n\ncd ../.. moves you up two levels.\n\nThe . symbol means “the current directory”. You will often see it when running programs that should use the current folder as their starting point.\nAs you practice, pay attention to the prompt in your terminal. It often shows your current directory or at least the last part of the path. This small detail helps you keep track of where you are working.\n\n\n2.5.3 Managing Files and Folders\nThe command line also lets you create, move, and delete files and folders. At first, these actions may feel risky, but they quickly become a precise way to organize your projects.\nCommon commands include:\n\nmkdir &lt;name&gt; — create a new folder\n\ntouch &lt;filename&gt; — create an empty file\n\nrm &lt;filename&gt; — remove a file\n\nrm -r &lt;folder&gt; — remove a folder and everything inside\n\ncp &lt;source&gt; &lt;destination&gt; — copy a file\n\nmv &lt;old&gt; &lt;new&gt; — rename or move a file\n\nClear and consistent naming makes your work easier to understand and avoids errors later, especially when your projects grow. Good naming practices for data science include:\n\nUse lower case whenever possible (data/, not Data/).\n\nAvoid spaces, which cause trouble in the terminal (raw_data, not raw data).\n\nUse dashes or underscores, but pick one and stay consistent (weather-data or weather_data).\n\nAvoid special characters such as !, ?, *, #, or &.\n\nPrefer short, descriptive names (scripts/, figures/, clean.py).\n\nOrganize by purpose, not by date alone. Use folders like data/, scripts/, projects/, and output/.\n\nKeep related files together, and avoid scattering pieces of the same project across unrelated locations.\n\nGood naming makes your work predictable—for you, your future self, and anyone you collaborate with. It also reduces mistakes when writing paths or running scripts from the terminal.\n\n\n2.5.4 Running Programs from the Terminal\nThe command line can also start programs and check whether your tools are installed correctly. Examples include:\n\ncode . — open the current folder in VS Code\n\ngit --version — check that Git is installed\n\npython --version — check your Python installation\n\nR --version — confirm that R is available\n\nquarto check — verify that Quarto is installed correctly\n\nLaunching programs from the terminal reinforces the idea that your computer is programmable. It also prepares you for workflows where scripts and tools need to run together smoothly.\n\n\n2.5.5 Mini-Project: Creating Your First Data Science Workspace\nTo make these ideas concrete, you will now create a simple workspace for your future projects.\n\nOpen the Terminal\nOn Windows, start Git Bash. On macOS or Linux, open the Terminal app.\nFind Your Home Directory\nRun pwd to display your current working directory.\nIf you are not already in your home directory, move there using cd ~.\nMake a ds4hs Folder\nCreate a directory named ds4hs with mkdir ds4hs.\nMove into it using cd ds4hs.\nConfirm that you are in the right place by running pwd.\nAdd a Few Subfolders\nInside ds4hs, create directories named data, analysis, and figures.\nCheck your work with ls to ensure they appear.\nPractice Moving Around\nChange into the data directory with cd data.\nMove back to ds4hs with cd ...\nTry moving directly to figures using cd figures.\nMove up one level with cd ...\nReturn to the previous directory using cd -.\nOpen a Project Folder in VS Code\nFrom inside the ds4hs directory, open the project in VS Code by running\ncode .\n(If necessary, enable the “code” command in VS Code.)\nCreate a Small Project Template\nInside ds4hs, create a folder named mini_project.\nWithin it, create subfolders data, analysis, and figures.\nAdd an empty Quarto file using touch analysis/analysis.qmd\nand an empty CSV file using touch data/example.csv.\nUse ls -R to display the full directory structure.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "02-computer.html#exercises",
    "href": "02-computer.html#exercises",
    "title": "2  Your Computer as a Tool for Discovery",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\nCheck Your Location\nOpen Git Bash or Terminal and run pwd.\nWrite down the full path and circle the folder you are currently in.\nList Folder Contents\nUse ls to display the files and folders in your working directory.\nThen run ls -l and note at least two new pieces of information you see compared with ls.\nCreate a Project Directory\nNavigate to your home directory using cd ~.\nCreate a folder named ds4hs with mkdir ds4hs.\nMove into it with cd ds4hs and verify your location using pwd.\nBuild a Basic Folder Structure\nInside ds4hs, create subfolders for data, analysis, and figures.\nUse ls to confirm that the folders were created.\nPractice moving between them with cd, cd .., and cd -.\nOpen a Project Folder in VS Code\nFrom inside the ds4hs directory, open the project in VS Code by running\ncode .\n(If necessary, enable the code command in VS Code.)\nIn the VS Code terminal, run ls -R to display the full directory structure.\n\n⭐ Challenge (optional):\nInside ds4hs, create a folder named mini_project with subfolders data, analysis, and figures. Add an empty Quarto file using touch analysis/analysis.qmd and an empty CSV file using touch data/example.csv. Use ls -R mini_project to check that everything is in the right place.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Your Computer as a Tool for Discovery</span>"
    ]
  },
  {
    "objectID": "03-tools.html",
    "href": "03-tools.html",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "",
    "text": "3.1 Your Editing Home: Visual Studio Code\nThis chapter introduces tools that support reproducible and organized data science work. You will use VS Code, Git, GitHub, and Quarto throughout the book.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  },
  {
    "objectID": "03-tools.html#your-editing-home-visual-studio-code",
    "href": "03-tools.html#your-editing-home-visual-studio-code",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "",
    "text": "3.1.1 What an IDE Is and Why VS Code\nA code editor is more than a place to type. An Integrated Development Environment (IDE) brings together tools that help you write, run, and organize code efficiently. Unlike simple editors such as Notepad or TextEdit, an IDE understands your project structure, highlights syntax, suggests fixes, and connects directly to version control.\nVS Code is widely used in data science because it is fast, lightweight, and highly customizable. It includes an integrated terminal, a built- in file explorer, and a rich extension system that adds support for Python, R, Git, Quarto, and Markdown. These features allow you to work productively without switching between different applications.\n\n\n3.1.2 Installation and Setup\nTo install VS Code, visit the official website at https://code.visualstudio.com and download the installer for your operating system. On Windows, choose the System Installer (64-bit) and follow the default installation steps. On macOS, you may download the installer from the same page or install VS Code through Homebrew using\nbrew install --cask visual-studio-code\nAfter installation, open VS Code and add several key extensions that support data-science work. You can install them by clicking the Extensions icon in the sidebar or by opening the command palette (Ctrl/Cmd + Shift + P) and selecting “Extensions: Install Extensions.”\n\nPython — Provides autocomplete, linting, debugging, and notebook support for Python scripts.\nR — Adds tools for editing and running R code directly from VS Code.\nGitLens — Enhances the Git interface with commit history, blame information, and comparisons.\nQuarto — Enables authoring of reproducible documents, reports, and slides in Quarto.\nMarkdown Shortcuts — Offers convenient formatting commands for Markdown and Quarto editing.\n\nVS Code also includes a built-in terminal so you can run command-line tools without switching windows. Open it by choosing View → Terminal from the menu or by pressing Ctrl+(Control + backtick). From there you can run commands such ascd,ls,git status, orpython` inside your project.\nOn Windows, you may want VS Code to use Git Bash instead of PowerShell. After installing Git for Windows, open the command palette (Ctrl/Cmd + Shift + P), choose “Preferences: Open User Settings (JSON),” and add the following entry:\n\"terminal.integrated.defaultProfile.windows\": \"Git Bash\"\nYou can now run cd, ls, git status, and other commands in a familiar Unix-like environment directly inside VS Code.\n\n\n3.1.3 Navigating VS Code\nA core habit in VS Code is opening a folder instead of individual files. When you open a folder as a project, VS Code tracks your files, recognizes your structure, and keeps your work organized. This makes it easier to manage assignments, scripts, and datasets in one place. The sidebar provides access to the file explorer, global search, and version control. The command palette (Ctrl/Cmd + Shift + P) is one of the fastest ways to work, allowing you to run nearly any command without searching through menus. VS Code also supports multiple editor panes for side-by-side editing, and it offers an excellent environment for Markdown and Quarto documents.\n\n\n3.1.4 Best Practices\n\nAlways work inside a project folder such as ds4hs/.\nKeep everything in plain text, including scripts, notes, and Quarto documents.\nTurn on autosave and consider enabling format-on-save for clean, consistent files.\nAvoid storing files on the desktop; keep all work organized under your project directory.\n\n\n\n3.1.5 Exercises\n\nOpen the ds4hs folder in VS Code.\nCreate a new Markdown file and write a short paragraph in it.\nUse the command palette to install an extension.\nOpen the integrated terminal and run ls to view your project files.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  },
  {
    "objectID": "03-tools.html#version-control-with-git-your-projects-memory",
    "href": "03-tools.html#version-control-with-git-your-projects-memory",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "3.2 Version Control with Git: Your Project’s Memory",
    "text": "3.2 Version Control with Git: Your Project’s Memory\n\n3.2.1 Essential Git Commands\n\ngit init initializes a repository.\ngit status shows changes.\ngit add stages files.\ngit commit -m \"message\" records changes.\ngit diff displays differences.\ngit push sends changes to GitHub.\ngit pull retrieves updates.\n\nVersion control is a foundational skill for data science because it treats your work as a living project with a complete history. Git lets you track every change you make, revert mistakes, create experimental branches, and collaborate without overwriting anyone’s work. Unlike saving multiple file versions by hand (e.g., project_final_v12_REAL), Git provides a precise, automatic timeline of your edits. This makes your work reproducible, auditable, and shareable — all essential habits for scientific computing.\n\n\n3.2.2 Why Git?\nGit offers a lightweight yet powerful system for managing all the changes in your project. It acts as “undo for your entire project,” not just for a single file, meaning you can always go back to a working state. For data science, reproducibility is everything: Git keeps a full record of how your analysis evolved, so others (and future you) can see exactly how results were produced. When working with classmates or research teams, Git prevents accidental overwriting and makes collaboration structured instead of chaotic.\n\n\n3.2.3 Getting Started\nInstalling Git - macOS: brew install git\n- Windows: Download Git for Windows (Git Bash included) from\nhttps://git-scm.com/downloads - Linux: Install from your system’s package manager\nAfter installation, configure Git the first time you use it:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your@email.com\"\nVerify everything is correctly installed:\ngit --version\ngit config --list\n\n\n3.2.4 Basic Workflow with Git Bash or VS Code\nGit works best when your project is organized as a clean folder containing scripts, Quarto files, and documentation.\nCommon Git commands:\n\ngit init — start a new repository in your current folder\n\ngit status — see what has changed\n\ngit add — stage changes\n\ngit commit — save changes with a message\n\nExample workflow:\ncd ds4hs\ngit init\ngit status\ngit add .\ngit commit -m \"first commit: added folder structure\"\nA .gitignore file helps you avoid uploading unnecessary files such as large raw datasets, temporary folders, or system files. A typical example:\ndata/\n*.csv\n*.DS_Store\n\n\n3.2.5 Working with GitHub\nGitHub is the online home for your Git repositories. It allows you to publish your work, share it with others, and sync across computers.\nTypical GitHub workflow:\n\nCreate a new repository on GitHub (empty, no README).\nConnect your local folder to that repository:\n\ngit remote add origin https://github.com/yourname/ds4hs.git\ngit branch -M main\ngit push -u origin main\n\nTo download someone else’s project:\n\ngit clone https://github.com/someone/project.git\n\n\n3.2.6 Exercises\n\nCreate a ds4hs folder (if not already created), initialize it as a Git repository, and make at least two commits showing meaningful progress.\nWrite a .gitignore file that excludes data, temporary files, or OS files on your system. Verify with git status that the ignored files do not appear.\nCreate a new GitHub repository and publish your ds4hs project using git push.\nClone a public GitHub repository of your choice. Explore its structure: identify where code, documentation, and data are stored.\nModify your ds4hs project by adding a README, commit the change, and push it to GitHub.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  },
  {
    "objectID": "03-tools.html#quarto-reproducible-documents-for-real-data-science",
    "href": "03-tools.html#quarto-reproducible-documents-for-real-data-science",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "3.3 Quarto: Reproducible Documents for Real Data Science",
    "text": "3.3 Quarto: Reproducible Documents for Real Data Science\n\n3.3.1 Why Quarto?\nQuarto is the modern tool for writing documents that combine text, code, figures, and results in one place. Instead of keeping separate Word files, screenshots, exported plots, and loose scripts, Quarto keeps everything together and reruns your analysis whenever data or code change. This makes work transparent, reproducible, and easy to review. Data scientists use Quarto because it replaces Word and PowerPoint entirely for technical documents, reports, and notebooks, and naturally forces better project habits. When teaching or doing projects, Quarto helps your work look professional while keeping the focus on reasoning and evidence rather than formatting.\n\n\n3.3.2 Installation and Setup\nTo use Quarto, you need two things:\n\nQuarto CLI\nDownload and install from https://quarto.org/docs/get-started This gives you the command-line tool quarto for rendering documents. After installation, verify:\nquarto check\nQuarto Extension in VS Code\nOpen the Extensions panel, search for Quarto, and install it. This adds syntax highlighting, preview tools, and convenient buttons for rendering.\nRendering formats\nWith the extension installed, you can render a .qmd file directly to HTML or PDF using the “Render” button in VS Code or by running\nquarto render myfile.qmd\nPDF output requires a LaTeX installation (TinyTeX or TeX Live); HTML works out of the box.\n\n\n\n3.3.3 Anatomy of a Quarto File\nA basic Quarto document has three components:\n\nYAML header\nAppears at the top between --- lines and controls title, author, format, and other options.\n---\ntitle: \"My Document\"\nformat: html\n---\nMarkdown body\nThis is where you write text, using the same Markdown syntax you already know: headings, emphasis, lists, links, and so on.\nCode chunks\nCode blocks that run during rendering and insert their results automatically. Quarto supports many languages.\n\n1 + 1\n\n[1] 2\n\n\n\nprint(\"hello quarto\")\n\nhello quarto\n\n\n\n\n\n3.3.4 First Reproducible Notebook\nA simple workflow for your first Quarto notebook:\n\nCreate a new file: my_first.qmd.\nAdd a YAML header, a few sentences of text, and a code chunk.\nAdd a small plot.\nRender to HTML.\n\nExample structure:\n---\ntitle: \"My First Quarto Notebook\"\nformat: html\n---\nWrite some text:\nThis is my first Quarto document. Below is a simple plot created in\nPython.\nInsert a plot:\n\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3], [1, 4, 9])\nplt.title(\"A Simple Plot\")\nplt.show()\n\n\n\n\n\n\n\n\nRender using the VS Code “Render” button or:\nquarto render my_first.qmd\n\n\n3.3.5 Exercises\n\nCreate a new .qmd file titled “My First Quarto Notebook.”\nAdd a YAML header with a title of your choice.\nWrite one paragraph explaining what your notebook will show.\nAdd a Python or R code chunk that produces a figure.\nRender to HTML and check that text, code, and output all appear.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  },
  {
    "objectID": "03-tools.html#python-and-optionally-r-your-first-programming-language",
    "href": "03-tools.html#python-and-optionally-r-your-first-programming-language",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "3.4 Python (and optionally R): Your First Programming Language",
    "text": "3.4 Python (and optionally R): Your First Programming Language\nPython is the most widely used language in modern data science, and it is an excellent first language for high school students. Its clean syntax allows beginners to focus on ideas instead of punctuation, and its large ecosystem means almost anything you want to do already has a library that helps you do it. For our purposes, Python will serve as the main tool for writing code, analyzing data, producing graphics, and connecting all of these pieces inside a Quarto notebook.\n\n3.4.1 Why Python for High School Data Science\nPython has earned its central place in data science because it balances power and readability. It comes with “batteries included,” meaning the basic installation already provides many useful tools. Its syntax reads almost like English, making it easier to learn than most languages. Most importantly, the Python ecosystem is enormous — libraries like pandas for data analysis, matplotlib and seaborn for plots, and scikit-learn for machine learning allow students to progress quickly from small ideas to real discoveries. While R is also a strong choice, especially for statistics, this book will use Python as the default and treat R as an optional companion language.\n\n\n3.4.2 Installing Python\nYou have two reliable options for installation, and either one works well in practice.\n\nOfficial Python installer (python.org) Best if you prefer a clean, minimal installation. Steps:\n\nVisit https://www.python.org/downloads/\n\nDownload the version recommended for your system\n\nRun the installer and make sure to check “Add Python to PATH” on Windows\n\nAnaconda distribution Best if you want many scientific libraries already installed. Steps:\n\nVisit https://www.anaconda.com/products/distribution\n\nDownload the installer for your system\n\nInstall with the default recommended settings\n\n\nAfter installation, verify that Python works by opening Git Bash or Terminal and typing:\npython --version\nYou should see something like Python 3.12.1. If you see an error, revisit the installation steps.\n\n\n3.4.3 Learning the Basics\nPython programming begins with building blocks. Students should spend time in a Quarto notebook writing small code chunks, running them, and modifying them to observe how the machine responds.\nCore building blocks to practice * Variables and basic types python   x = 5   name = \"Ada\"   pi = 3.14159\n\nLists\nnumbers = [1, 2, 3, 4, 5]\nDictionaries\nstudent = {\"name\": \"Hana\", \"grade\": 10, \"favorite_color\": \"blue\"}\nReading data Using pandas after installing it:\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\nSimple visualization\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4], [10, 15, 13, 17])\nplt.show()\n\n\n\n3.4.4 Jupyter vs Quarto Code Chunks (Use Quarto Only)\nPython is often taught using Jupyter notebooks, but this book will use Quarto notebooks exclusively. Quarto lets you combine code, text, figures, and explanations in one source file that produces polished HTML or PDF output. It is more powerful, more reproducible, and easier to use with version control.\nA sample Quarto Python chunk:\nimport pandas as pd\ndf = pd.read_csv(\"data/example.csv\")\ndf.head()\nStudents should write, run, and document their work entirely within Quarto. This reinforces good habits from the beginning and keeps every project reproducible.\n\n\n3.4.5 Exercises\n\nCreate a new Quarto document and write a few Python lines that define variables, lists, and dictionaries.\nInstall Python and verify your installation with python --version.\nRead a small CSV file into a pandas DataFrame and plot one column.\nModify the sample plot code to change colors, labels, or data.\nAdd a short paragraph in your Quarto file describing what you learned.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  },
  {
    "objectID": "03-tools.html#putting-it-all-together-your-first-data-science-project",
    "href": "03-tools.html#putting-it-all-together-your-first-data-science-project",
    "title": "3  Setting Up Your Data Science Toolkit",
    "section": "3.5 Putting It All Together: Your First Data Science Project",
    "text": "3.5 Putting It All Together: Your First Data Science Project\nThis chapter integrates everything from Part I—command line, VS Code, Git, GitHub, Quarto, and Python/R—into a single, coherent project workflow. The goal is to let students experience how real data science work is done: create a clean folder, version it with Git, write a reproducible Quarto file, and share the final analysis.\n\n3.5.1 Choosing a Simple, Meaningful Dataset\nThe first step in any project is choosing a dataset that is small, clean, and intrinsically interesting. Students should select something they care about so they remain motivated while practicing the workflow. Good examples include:\n\nNYC 311 complaint counts for a single neighborhood\nSchool lunch nutrition data from USDA open data\nA small sports dataset (NBA scores, soccer goals, WNBA box scores)\nTrends in daily steps from a personal fitness tracker\nAny two-column CSV they record themselves (date + measurement)\n\nBest practice is to avoid large, messy datasets for this first project. Students should aim to complete end-to-end analysis, not get stuck in heavy cleaning.\n\n\n3.5.2 Setting Up the Project Folder\nA clean folder structure helps keep the project reproducible and organized. Students use the command line to create folders and set up a Git repository.\nRecommended structure:\n\ndata/ — raw datasets in CSV or JSON\nanalysis/ — Quarto notebooks\nfigures/ — automatically generated plots\nREADME.md — short description of the project\n\nKey steps:\n\nUse the command line to create the folder and subfolders\n(mkdir ds4hs-project, cd ds4hs-project, mkdir data analysis figures)\nInitialize Git with\ngit init\nMake the first commit with\ngit add . and git commit -m \"Initial project structure\"\n\nStudents should verify that Git is tracking the project by running git status and confirming the working tree is clean.\n\n\n3.5.3 Writing a Full Quarto Analysis\nThe core of the project is a reproducible Quarto notebook that explains the data, code, and conclusions in one document. The notebook should include:\n\nA clear statement of the question (e.g., “How do 311 noise complaints differ between weekdays and weekends?”)\nCode to import the dataset\nTwo or three meaningful visualizations (bar plots, line plots, scatterplots, histograms)\nShort summary paragraphs explaining the patterns\n\nA minimal workflow:\n\nCreate analysis/project.qmd in VS Code.\nAdd a YAML header with a title, author, and format.\nInsert code chunks to load the dataset and inspect its structure.\nGenerate plots and save outputs to the figures/ folder.\nRender the notebook to HTML using the VS Code Quarto extension.\n\nStudents should keep text and code in one place—not separate PowerPoints, Word files, or screenshots. Quarto ensures everything is reproducible.\n\n\n3.5.4 Publishing or Sharing Work\nOnce the analysis renders cleanly, students can make the project public (or share privately).\nOptions include:\n\nPush the project to GitHub with\ngit add ., git commit, and git push\nShare the rendered HTML via a GitHub repository\nOptionally, enable GitHub Pages so the report becomes a public website at https://username.github.io/ds4hs-project\n\nThis final step completes the full data science cycle: version control, reproducible notebook, and public sharing.\n\n\n3.5.5 Exercises\n\nChoose one dataset from the list above (or another small dataset that interests you). Add it to the data/ folder.\nBuild the full folder structure using only the command line.\nInitialize a Git repository and make at least two commits: one for the structure and one for adding your dataset.\nCreate a Quarto notebook that loads the data and produces at least two visualizations.\nPush your finished project to GitHub and share the link with your class.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Setting Up Your Data Science Toolkit</span>"
    ]
  }
]